{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data so that the target includes both stock and bond returns.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch\n",
    "\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "# Example DataFrame creation\n",
    "data = {\n",
    "    'stock_return': np.random.randn(100),\n",
    "    'bond_return': np.random.randn(100),\n",
    "    'CPI': np.random.randn(100),\n",
    "    'future_stock_return': np.random.randn(100),\n",
    "    'future_bond_return': np.random.randn(100)  # additional target variable\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Normalize the features and targets\n",
    "scaler_features = MinMaxScaler()\n",
    "scaled_features = scaler_features.fit_transform(df[['stock_return', 'bond_return', 'CPI']])\n",
    "\n",
    "scaler_target = MinMaxScaler()\n",
    "scaled_target = scaler_target.fit_transform(df[['future_stock_return', 'future_bond_return']])\n",
    "\n",
    "# Create sequences for LSTM input\n",
    "def create_sequences(data, target, seq_length):\n",
    "    sequences = []\n",
    "    targets = []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        seq = data[i:i+seq_length]\n",
    "        label = target[i+seq_length]\n",
    "        sequences.append(seq)\n",
    "        targets.append(label)\n",
    "    return np.array(sequences), np.array(targets)\n",
    "\n",
    "SEQ_LENGTH = 10\n",
    "X, y = create_sequences(scaled_features, scaled_target, SEQ_LENGTH)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "dataset = TensorDataset(X_tensor, y_tensor)\n",
    "dataloader = DataLoader(dataset, batch_size=16, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Update the model to handle multiple outputs (both stock and bond returns).\n",
    "\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(num_layers, x.size(0), hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(num_layers, x.size(0), hidden_size).to(x.device)\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "input_size = 3  # number of features: stock_return, bond_return, CPI\n",
    "hidden_size = 50\n",
    "num_layers = 2\n",
    "output_size = 2  # predicting both stock and bond returns\n",
    "\n",
    "model = LSTMModel(input_size, hidden_size, num_layers, output_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 0.2266\n",
      "Epoch [2/20], Loss: 0.1136\n",
      "Epoch [3/20], Loss: 0.0310\n",
      "Epoch [4/20], Loss: 0.0386\n",
      "Epoch [5/20], Loss: 0.0316\n",
      "Epoch [6/20], Loss: 0.0395\n",
      "Epoch [7/20], Loss: 0.0366\n",
      "Epoch [8/20], Loss: 0.0306\n",
      "Epoch [9/20], Loss: 0.0230\n",
      "Epoch [10/20], Loss: 0.0410\n",
      "Epoch [11/20], Loss: 0.0288\n",
      "Epoch [12/20], Loss: 0.0271\n",
      "Epoch [13/20], Loss: 0.0437\n",
      "Epoch [14/20], Loss: 0.0477\n",
      "Epoch [15/20], Loss: 0.0122\n",
      "Epoch [16/20], Loss: 0.0481\n",
      "Epoch [17/20], Loss: 0.0311\n",
      "Epoch [18/20], Loss: 0.0366\n",
      "Epoch [19/20], Loss: 0.0250\n",
      "Epoch [20/20], Loss: 0.0174\n"
     ]
    }
   ],
   "source": [
    "# Train the model with the updated setup.\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 20\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for X_batch, y_batch in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.02639892 -0.04806899]]\n"
     ]
    }
   ],
   "source": [
    "# Make predictions for both stock and bond returns.\n",
    "\n",
    "# To make predictions\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    sample_input = torch.tensor(X[:1], dtype=torch.float32)\n",
    "    prediction = model(sample_input)\n",
    "    prediction = scaler_target.inverse_transform(prediction.numpy())  # Convert back to original scale\n",
    "    print(prediction)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this updated example:\n",
    "\n",
    "1. **Data Preparation**: Both `future_stock_return` and `future_bond_return` are included as targets.\n",
    "2. **Model Definition**: The output size of the LSTM model is set to 2 to predict both returns.\n",
    "3. **Training**: The training loop remains the same, but now the model predicts multiple targets.\n",
    "4. **Prediction**: Predictions are scaled back to the original range for interpretability.\n",
    "\n",
    "Make sure to adapt the `input_size`, `output_size`, and other parameters according to your specific dataset and requirements."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
